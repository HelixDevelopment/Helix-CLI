<!DOCTYPE html>
<html>
<head>
<title>CLI_Specs.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<p><img src="file:///Users/milosvasic/Projects/Helix-CLI/Assets/Wide_Black.png" alt="JIRA alternative for the free world!"></p>
<h1 id="helix-cli-specs">Helix CLI Specs</h1>
<p>The Helix CLI is the AI coding agent built for the terminal to access and work (code, test, debug, etc.) with LLMs. Primary provider is LLama CPP, however it supports all other options such as work with remote APIs - DeepSeek, Qwen, Claude, Gemini, Grok, Mistral, etc. It supports various other providers like OpenRouter, Ollama, Nvidia, HuggingFace, etc.</p>
<p>It is powerfull programming tool which intracts with end user and makes possible flawless code implementation on the projects, refactopring, debugging, etc.</p>
<h2 id="dynamic-hardware-analysis-and-optimization">Dynamic hardware analysis and optimization</h2>
<p>The CLI makes possible for end users to build and run local LLMs and use them for code generation, testing, debugging, etc. However, most important is that Toolking, Thinking and other LLM capabilities may be flwalessly used on low end computer systems (by using 7B LLMs). On more capable machines, dynamically detrmined, more powerful LLMs may be used - 32b and similar.</p>
<h2 id="architecture">Architecture</h2>
<p>All project / application components are fully decoupled programs which are bound together with proper bash scripts. Each comonent can be used separately or as a part of larger application bound together by bash scripts. All programs are writtent in Go language.</p>
<p>Some of the components that we are mentioning now are:</p>
<ul>
<li>LLama CPP API for communication with LLMs executed locally by LLama CPP</li>
<li>OpenRouter API for communication with OpenRouter</li>
<li>Ollama API for communication with Ollama</li>
<li>DeepSeek API for communication with DeepSeek</li>
<li>Qwen API for communication with Qwen</li>
<li>Claude API for communication with Claude</li>
<li>Other APIs for communication with other LLMs</li>
<li>ASII art generator - will generate the header for the project that will appear in CLI UI when user starts the application</li>
<li>Pure CLI mode (Headless CLI mode)</li>
<li>CLI UI mode</li>
<li>REST API mode (run as server)</li>
<li>Postgres database component (run as server) - will be used by CLI UI and REST API, storing memories, progres, etc. Postgres database will be SQL Cipher protected!</li>
<li>Debugger component - make sure that debugging of software for issues detection is possible using LLMs. It investigates and collects information about software execution for further fixes and improvements or new features development.</li>
<li>Planner - Does the deep analysis and perfroms the planning with written documentation as result of this efforts - user inputs are required as always</li>
<li>Builder - Builds the code using LLMs, extends the features, fixes issues, etc.</li>
<li>Refactorer - Refactors the code using LLMs, extends the features, fixes issues, etc.</li>
<li>Tester - Tests the code using LLMs, extends the features, fixes issues, etc. Tester introduces to the codebase of single or multiple modules of the projects the full 100% code coverage with several testing types: unit, integration, full automation, end-to-end, etc. Last two types will always be executed on real devices or emulators or apps ran by real AI QA! There are two more kind of tests that will always be performed: SoanrQube deep scanning and Snyk. Both performed with dockerized (docker compose) free versions of the two tools. Full reports will be generated and any discovered issues fully fixed.</li>
</ul>
<h2 id="llama-cpp-and-ollama-support">LLama CPP and Ollama support</h2>
<p>Under the hood API will contain its local instance (codebase) of LLama CPP and Ollama. It will be used for communication with LLMs via exposed API. Once it is ready it will be used for communication with LLMs. To be ready it has to download source code, do optimal build for current OS, do the configuration and optimization. API will expose downloadable LLMs for both LLama CPP and Ollama. It will download LLMs from all possible sources such as HuggingFace, OpenRouter, DeepSeek, Qwen, Claude, etc. Downloaded LLMs will be converted to proper format if that is needed so LLama CPP and Ollama will be able to use them.
User will trigger the installation of the LLM and it will be ready for use. Installation will first make sure to detect hardware of host machine - all mandatory capabilites, then it will build local project instance of LLama CPP and Ollama and will download the LLM to be used. All optimization performed and LLM downloaded and started.</p>
<p>All utils have to be decoupled and other components for installation, configuration, download and running the LLMs. Make sure we have proper generics and interfaces which are widely reusable! Resusability principle has to be followed with every project component!</p>
<h3 id="others-apis---vllm-local-llm-etc">Others APIs - VLLM, Local LLM, etc</h3>
<p>Same principle we described for LLama CPP and Ollama will be applied to other platforms and their LLMs.</p>
<h2 id="cli-terminal-ui-features">CLI (Terminal UI) features</h2>
<ul>
<li>Testing</li>
<li>Refactoring</li>
<li>Planning</li>
<li>Builder (Code generation) - Creates the code using LLMs. It spwans multiple builders which will split the codebase into modules and generate the code for each module. Each worker (LLM builder) will generate the code for single module.
All this will be done in parallel and synchornized. Default number of workers (builders) is one. User can set the number of workers to be used. There will be another builder running - the coordinator which will accept work done by workers and put it properly so no conflicts happen!</li>
<li>Refactorer - Performs codebase refactoring</li>
<li>Tester - Executes all available tests, brings up all required apps and emulators as precoditions, generates reports, fixes discovered issues and finall does the SonqrQube and Snyk scanning.</li>
<li>Debugger</li>
<li>Diagrams (creation of UML diagrams and others from the Project and its docs and source code in supported formats - drawio, Mermaid.js, png, jpeg, uml, pdf, etc.) Default is drawio.</li>
<li>Deployment (deploying the project to the cloud or any other defined endpoint)</li>
<li>Default project is the current directory</li>
<li>If no Helix.md is available user will be asked to allow creation of it
<ul>
<li>Creation will scan the whole project up to the details and write to the file</li>
<li>Format and rules are same as for AGENTS.md or CLAUDE.md</li>
<li>If any existing file is found of other agents like CLaude or OpenCode it will be used to support the project's Helix.md generation</li>
<li>We will detect all sub-projects and modules. For each of it individual agent file (Helix.md) will be created</li>
</ul>
</li>
<li>User is able to switch between projects and modules (into deeper hierarchy and to go back)</li>
<li>User is able to send command sequentially (requests) to the CLI agent which will execute them</li>
<li>Using tab user can switch between the modes (Builder and others)</li>
<li>User will be asked about every action that agent is going to do such as write into the file, execute the system command, util, etc. There will be option to skip, accept, accept for the whole session, accept forever for the current project</li>
<li>All configuration and choices are going to be written in json configuration file: ~/.config/Helix/helix.json</li>
<li>User will be able to switch modles by choosing provider (LLama CPP, DeepSeek, Qwen, Claude, etc.) and proper model (this will be stored in helix.json file as setting)</li>
<li>All this operation will be dopne by proper set of commands sent to the agent, we will use a exact same command like Crush has with some differences: we will be able to paste from clipboard request that we want to send; we are going to be able to repeat all requests sent to agent. All requests will be stored in Postgres database using dagtabse component. The whole history of requests will be rememebred so we can scroll through it and repeat any request.</li>
<li>User will be able to add requests from history to favorites and to group them! There will be command / section so user can pick some and execute regularly! All this is going to be sotred in the database</li>
<li>Export and import of helix.json and the database will be possible - in sql and json formats</li>
<li>Theming - Default theme will be based on default ascii code generated LOGO presented at the top of Terminal UI. It will be in green-ish colors. However we will have the following color themes which user can change too: warm red, blue, green, yellow, gold, grey, white, darcula, dark blue, violet, warm orange, etc.
User will be able to clone the theme and change the value, save the theme under the new name. All this will be stored in the database and will be loaded when user starts the application.</li>
<li>Pause / Resume / Detach - User will be able to pause working session and to continue it later! Also, it will be able to detach from it which will not interrupt current session but will allow to continue in the background (non-interactive mode with all questions and permissions accepted).</li>
<li>Rollback - User will be able to rollback to the previous state of the project! By chosing one of requests that have been completed all work of it will be reverted. User can chose chained rollback - to rollback the request done (changes) and everything that has later been done (other requests) with relation to it, or just rollback the single request work done. No module can stay disabled or broken or the test so in this operation mode all polishing and fixing will be performed to have project in usable stable state after the rollback work has been done.</li>
</ul>
<h3 id="cli-headless-features">CLI (Headless) features</h3>
<ul>
<li>All above but without UI - executed interactively or non-interactively (non-interactive mode is useful for automation and default one)</li>
</ul>
<h3 id="rest-api-features">REST API features</h3>
<ul>
<li>All above but without UI - executed interactively or non-interactively (non-interactive mode is useful for automation and default one) through REST API</li>
</ul>
<h3 id="session-work">Session work</h3>
<ul>
<li>All started work will define a session</li>
<li>Session can have a name</li>
<li>All active session within a Helix agent will be stored in the database</li>
<li>It will be possible to join to existing session using proipe &quot;join&quot; command and interacti with it from multiple places - for example user is connected via SSH or REST API from various computers. All this must work.</li>
<li>It will be possible to kill session which is stuck or we do not want it anymore with command &quot;kill&quot; passed to Helix CLI from the terminal</li>
<li>It will be possible to list all active sessions with command &quot;sessions&quot;</li>
<li>Filtering sessions by active, stuck, completed, etc.</li>
<li>Session monitoring - show commands executed by the agent and their results, cpu and memory usage, etc. (&quot;monitor&quot; command)</li>
</ul>
<h2 id="memory">Memory</h2>
<p>All work done will be stored in database in several layers as working memory so LLMs will be able to use it and continue where they left of! The structire of remembering will be Project -&gt; All done so far -&gt; Current sessions -&gt; Current work in progress. Once user re-executes the request, or types similar one and sends it to execution, system will recognize it as already in progress and will not execute it again! It will update on current status after check and next steps, then continue with work. If there is no such work done on project at the moment fresh new operation will be done to achieve golas from the request sent.</p>
<h2 id="testing">Testing</h2>
<p>Testing mode will be specifically used to test modules and project - running all tests, providing it all mandatory dependencies and writing test reports. All discovered issues will be resolved until 100% of tests is executed with succes.
Mandatory SonarQube and Snyk testing will be performed.</p>
<h3 id="project-testing">Project testing</h3>
<p>All codebase of Helix CLI must be covered with all test types mentioned in this document. All test types must have coverage of codebase of 100%. Every single test and test case must execute 100% with success! It is mandatory to verify everything with SonarQube intensive deep testing and Snyk! Both will be performed with free versions (docker compose containers). Reports will be generated and any discovered issues will be fixed.</p>
<h2 id="documentation">Documentation</h2>
<p>For all features, modules, components, tests, everything must be created proper and detialed documentation. We must support end users documentation and developers documentaton. Every single document written has to be available in pure nicely styled too!</p>
<h2 id="diagrams">Diagrams</h2>
<p>In this mode user will be able to create diagrams in proper format for entire project and for specific modules. Default export format is drawio, but user may want to export into a different one or multiple formats at the same time. All this will be supported and will be available in the project.</p>
<p>Helic CLI itself will have allk diagrams generated and ready for users to analyse. We must have them all integrated as the part of the documentation - Mermaid.js
io markdowns.</p>
<h2 id="deployment">Deployment</h2>
<p>In deployment mode user will be able to cretae deploymewnt profiles which will be executed and project to be delivered to the cloud or any other defined endpoint.</p>
<p>Helix CLI will be possible to build and deploy for all operating systems as the multiplatform solution.</p>
<h3 id="supported-deployments-and-flavors">Supported deployments and flavors</h3>
<p>As we have mentioned we will have default Terminal UI CLI Agent, but pure CLI (Headless) as well. All this to run efficiently on all major operating systems such as: Linux, macOS, BSDs, Windows.</p>
<p>REST API flavor will have several client adaptations so on top of this the following clients will be implemented to cover all features offered by the Terminal UI! Web client, Desktops and Mobile apps. They will all access the local or remote REST API endpoints (which could be local host by default or configurable remote instance).</p>
<h2 id="automation-scripts">Automation scripts</h2>
<p>All steps - building, testing, generating the documentation, diagrams, etc. will be fully automatized by proper bash scripts.</p>
<h2 id="launcher-icon">Launcher icon</h2>
<p>Whenever Helix CLI process in some of its forms is running to the user in its operating system proper icon in some form (launcher icon) will be presented. For that purpose generate the icon(s) from the Logo.png from the Assets folder.</p>
<h2 id="unsorted-points">Unsorted points</h2>
<p>These points have to be assigned as extension to the sections and points from above</p>
<ul>
<li>Design - Besides Plan, Build, etc we have another one mode - Design. It creates all designs in Figma and Penpot formats
<ul>
<li>Import Figma created designs into the Figma project via connected Figma account (if any available)</li>
<li>Penpot as well</li>
<li>Figma and Penpot configuration wizrd as part of every Helix CLI variant - Terminal UI, CLI, REST API, etc.</li>
<li>Figma and Penpot configuration will be part of helix.json configuration</li>
</ul>
</li>
<li>Any design change we do creates new new version which is then imported into Figma project using the API</li>
<li>Design mode: Import from Figma and Apply to the project
<ul>
<li>Having possibility of syncing changes in both directions</li>
<li>Same applies for the Penpot</li>
</ul>
</li>
<li>Modes flow - Modes can call each other during the development and realisation of the requests (modes may produce various results), each called mode will use its worker LLM model</li>
<li>Hierarchy if mode calls with workers working in them always presented. Also hierarchi relative to project -&gt; module -&gt; submodule -&gt; modes calls (add this into the architecture)</li>
<li>Models - one for all modes or different or mixed per mode, dynamic obtained as well (determine which available model is most proper for current mode - Planner, Builder, etc.)</li>
<li>Create use cases, all flows, all edge cases, documented as real tests to be implemented in e2e and full-automation tests.</li>
<li>helix cli dockerization with exposed clis - proper documentation</li>
<li>Predefined mode flows: planning -&gt; building -&gt; testing -&gt; deployment or, create flow dynamically - start the planning mode from which will be decided how the whole implementation flow will look like, then run it</li>
<li>Log everything into the database
<ul>
<li>Logs viewer (load logs from the whole project, whole module, session, individual request or any step) for analysis and research</li>
<li>Support proper filtering</li>
</ul>
</li>
<li>Clients - Each client will be able to: browse projcts, modules, sessions or indicidual requests and then to join them or manipulate each of it remotely (using REST API)
<ul>
<li>Every running process of Helix CLI will bring up REST API whoch will be able to be used by the clients</li>
<li>REST API will bind to default port or port from the helix.json configuration. If it is taken, it will bind to the first next abailable port</li>
<li>REST API and clients will support broadcasting of configuration and discovery of service. All client apps will be able to chose between discovered REST API instances or to configure one manually.</li>
</ul>
</li>
<li>Hardware analysis which is base for selection of proper model and its size will be perfrormed deeply and all detected hardware maximally utilized - vram, ram, cpus, etc.</li>
<li>Obtain details and capabilities from models and providers dynamically - context size allowed, api detials, etc. Based on this our API will be able to be used for all modes and to send proper instructions - Tooling and Thinkng, etc.</li>
<li>Problems tollerance handling - To fail if problems arise, or to try to fix them - this is the default setting (settings for this go in helix.json).</li>
<li>Join by QR code - User will be to join session from other terminal or device by QR code.</li>
<li>Obtain all models from OpenCode - Zen provider - Free first - Incorporate all free models and other supported from OpenCode Zen (API, etc.)</li>
<li>Sharing - Access to Project, Session, etc (protected with credentials if accounts available - optional) - We must be able to share whole project, module, session, etc. by link. If accounts available - we must be able to share by account / credentials protection so that only authorized user will be able to access it.</li>
<li>Accounts management (optional) - Create account, login, logout, etc. Accounts will have permissions to access projects, modules, sessions, etc. All this has to be configurable. Settings for this will go in Postgres datrabase.</li>
<li>Rest uses http3 - All REST API will use http3 / quic / cronet and all clients that will communicate with it</li>
<li>One model for modes - single vs multi instance</li>
<li>Porting mode</li>
<li>Fallback models</li>
<li>Models configuration wizard for project, module, etc.</li>
<li>Multiple api keys support</li>
<li>Models processes manager / monitor with performance monitoring and alerts</li>
<li>Delegating work to multiple machines - nodes (slaves) - instead of join command to have connect or similar</li>
<li>Remote share connect</li>
</ul>
<h3 id="finally">Finally</h3>
<ul>
<li>Reorganize and fill the gaps of specs doc so it is perfect specification</li>
<li>Create task units for ai impl.</li>
</ul>

</body>
</html>
